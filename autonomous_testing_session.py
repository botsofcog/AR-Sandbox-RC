#!/usr/bin/env python3
"""
Autonomous Testing Session - 20 Minute Deep Dive
Comprehensive testing, optimization, and validation while user is away
"""

import time
import json
import subprocess
import os
from datetime import datetime
from pathlib import Path

class AutonomousTestingSession:
    def __init__(self):
        self.session_start = datetime.now()
        self.session_duration = 20 * 60  # 20 minutes in seconds
        self.test_results = []
        self.optimizations_applied = []
        self.issues_found = []
        self.performance_metrics = []
        
    def log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {message}")
        
    def run_test_suite(self, test_name, command):
        """Run a test suite and capture results"""
        self.log(f"üß™ Running {test_name}...")
        start_time = time.time()
        
        try:
            result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=300)
            duration = time.time() - start_time
            
            test_result = {
                'name': test_name,
                'command': command,
                'duration': duration,
                'return_code': result.returncode,
                'success': result.returncode == 0,
                'stdout_lines': len(result.stdout.split('\n')),
                'stderr_lines': len(result.stderr.split('\n')),
                'timestamp': datetime.now().isoformat()
            }
            
            self.test_results.append(test_result)
            
            if result.returncode == 0:
                self.log(f"‚úÖ {test_name} completed successfully in {duration:.1f}s")
            else:
                self.log(f"‚ùå {test_name} failed with code {result.returncode}")
                self.issues_found.append(f"{test_name}: Return code {result.returncode}")
                
            return test_result
            
        except subprocess.TimeoutExpired:
            self.log(f"‚è∞ {test_name} timed out after 5 minutes")
            self.issues_found.append(f"{test_name}: Timeout")
            return None
        except Exception as e:
            self.log(f"üí• {test_name} crashed: {e}")
            self.issues_found.append(f"{test_name}: Exception - {e}")
            return None
    
    def run_performance_analysis(self):
        """Analyze system performance"""
        self.log("üìä Running performance analysis...")
        
        # Check file sizes and counts
        file_stats = {}
        for root, dirs, files in os.walk('.'):
            # Skip hidden and archive directories
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != 'archive']
            
            for file in files:
                ext = Path(file).suffix.lower()
                if ext not in file_stats:
                    file_stats[ext] = {'count': 0, 'total_size': 0}
                
                file_path = os.path.join(root, file)
                try:
                    size = os.path.getsize(file_path)
                    file_stats[ext]['count'] += 1
                    file_stats[ext]['total_size'] += size
                except:
                    pass
        
        # Performance metrics
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'file_statistics': file_stats,
            'total_files': sum(stats['count'] for stats in file_stats.values()),
            'total_size_mb': sum(stats['total_size'] for stats in file_stats.values()) / (1024*1024),
            'largest_file_types': sorted(file_stats.items(), key=lambda x: x[1]['total_size'], reverse=True)[:10]
        }
        
        self.performance_metrics.append(metrics)
        self.log(f"üìà Found {metrics['total_files']} files totaling {metrics['total_size_mb']:.1f}MB")
        
    def run_comprehensive_testing(self):
        """Run all available test suites"""
        self.log("üöÄ Starting comprehensive testing session...")
        
        # Test suites to run
        test_suites = [
            ("System Test - Quick", "python test_complete_system.py --quick"),
            ("System Test - Full", "python test_complete_system.py"),
            ("Markdown Formatting", "python fix_markdown_formatting.py"),
            ("Professional Demo List", "python professional_demo_suite.py --list"),
            ("Memory Optimization", "python scripts/memory_optimization.py"),
            ("Performance Monitoring", "python scripts/performance_monitoring.py"),
            ("Scalability Testing", "python scripts/scalability_testing.py"),
            ("CI/CD Validation", "python scripts/enhanced_ci_cd.py --validate"),
        ]
        
        for test_name, command in test_suites:
            if self.time_remaining() < 120:  # Stop if less than 2 minutes left
                self.log("‚è∞ Time running low, stopping test execution")
                break
                
            self.run_test_suite(test_name, command)
            time.sleep(2)  # Brief pause between tests
    
    def time_remaining(self):
        """Calculate remaining time in session"""
        elapsed = (datetime.now() - self.session_start).total_seconds()
        return max(0, self.session_duration - elapsed)
    
    def generate_final_report(self):
        """Generate comprehensive session report"""
        self.log("üìù Generating final autonomous testing report...")
        
        session_duration = (datetime.now() - self.session_start).total_seconds()
        
        report = {
            'session_info': {
                'start_time': self.session_start.isoformat(),
                'end_time': datetime.now().isoformat(),
                'duration_seconds': session_duration,
                'duration_minutes': session_duration / 60
            },
            'test_summary': {
                'total_tests': len(self.test_results),
                'successful_tests': len([t for t in self.test_results if t and t['success']]),
                'failed_tests': len([t for t in self.test_results if t and not t['success']]),
                'success_rate': len([t for t in self.test_results if t and t['success']]) / max(1, len(self.test_results)) * 100
            },
            'test_results': self.test_results,
            'performance_metrics': self.performance_metrics,
            'issues_found': self.issues_found,
            'optimizations_applied': self.optimizations_applied
        }
        
        # Save report
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"autonomous_testing_report_{timestamp}.json"
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Generate markdown summary
        summary_file = f"AUTONOMOUS_TESTING_SUMMARY_{timestamp}.md"
        with open(summary_file, 'w') as f:
            f.write(f"# Autonomous Testing Session Report\n\n")
            f.write(f"**Session Duration:** {session_duration/60:.1f} minutes\n")
            f.write(f"**Tests Run:** {len(self.test_results)}\n")
            f.write(f"**Success Rate:** {report['test_summary']['success_rate']:.1f}%\n\n")
            
            f.write(f"## Test Results\n\n")
            for test in self.test_results:
                if test:
                    status = "‚úÖ" if test['success'] else "‚ùå"
                    f.write(f"- {status} **{test['name']}** ({test['duration']:.1f}s)\n")
            
            if self.issues_found:
                f.write(f"\n## Issues Found\n\n")
                for issue in self.issues_found:
                    f.write(f"- ‚ö†Ô∏è {issue}\n")
            
            if self.performance_metrics:
                f.write(f"\n## Performance Metrics\n\n")
                latest_metrics = self.performance_metrics[-1]
                f.write(f"- **Total Files:** {latest_metrics['total_files']}\n")
                f.write(f"- **Total Size:** {latest_metrics['total_size_mb']:.1f}MB\n")
        
        self.log(f"üìÑ Reports saved: {report_file}, {summary_file}")
        return report
    
    def run_session(self):
        """Run the complete autonomous testing session"""
        self.log("ü§ñ Starting 20-minute autonomous testing session...")
        self.log(f"‚è∞ Session will run until {(self.session_start.timestamp() + self.session_duration)}")
        
        # Phase 1: Performance Analysis
        self.run_performance_analysis()
        
        # Phase 2: Comprehensive Testing
        self.run_comprehensive_testing()
        
        # Phase 3: Final Report
        report = self.generate_final_report()
        
        self.log("üéâ Autonomous testing session completed!")
        self.log(f"üìä Final Stats: {len(self.test_results)} tests, {report['test_summary']['success_rate']:.1f}% success rate")
        
        return report

def main():
    """Main entry point"""
    print("ü§ñ AR Sandbox RC - Autonomous Testing Session")
    print("=" * 60)
    print("Running comprehensive testing while user is away...")
    print("=" * 60)
    
    session = AutonomousTestingSession()
    
    try:
        report = session.run_session()
        print(f"\nüéØ Session completed successfully!")
        print(f"üìà {report['test_summary']['total_tests']} tests run")
        print(f"‚úÖ {report['test_summary']['success_rate']:.1f}% success rate")
        
    except KeyboardInterrupt:
        print("\nüõë Session interrupted by user")
    except Exception as e:
        print(f"\nüí• Session failed: {e}")

if __name__ == "__main__":
    main()
